<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Re-expression and Robustness</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #0000ff; } /* Keyword */
code > span.ch { color: #008080; } /* Char */
code > span.st { color: #008080; } /* String */
code > span.co { color: #008000; } /* Comment */
code > span.ot { color: #ff4000; } /* Other */
code > span.al { color: #ff0000; } /* Alert */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #008000; font-weight: bold; } /* Warning */
code > span.cn { } /* Constant */
code > span.sc { color: #008080; } /* SpecialChar */
code > span.vs { color: #008080; } /* VerbatimString */
code > span.ss { color: #008080; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { } /* Variable */
code > span.cf { color: #0000ff; } /* ControlFlow */
code > span.op { } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #ff4000; } /* Preprocessor */
code > span.do { color: #008000; } /* Documentation */
code > span.an { color: #008000; } /* Annotation */
code > span.cv { color: #008000; } /* CommentVar */
code > span.at { } /* Attribute */
code > span.in { color: #008000; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="libs\style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data Manipulation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Week 02</li>
    <li>
      <a href="Week02a.html">Data types</a>
    </li>
    <li>
      <a href="Week02b.html">Reading and writing data files</a>
    </li>
    <li>
      <a href="Week02c.html">Working with date objects</a>
    </li>
    <li>
      <a href="Week02d.html">Exploring and cleaning dataframes using base functions</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Week 03</li>
    <li>
      <a href="Week03a.html">Manipulating dataframes with dplyr</a>
    </li>
    <li>
      <a href="Week03b.html">Tidying/reshaping tables using tidyr</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Week 04</li>
    <li>
      <a href="Week03c.html">Joining data tables</a>
    </li>
    <li>
      <a href="Week03d.html">Working with string objects</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Plots
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Week 05</li>
    <li>
      <a href="Week04a.html">The base plotting environment</a>
    </li>
    <li>
      <a href="Week04b.html">The lattice plotting environment</a>
    </li>
    <li>
      <a href="Week04c.html">The ggplot plotting environment</a>
    </li>
    <li>
      <a href="Week04d.html">Manipulating colors in R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Univariate
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Week 06</li>
    <li>
      <a href="Week05a.html">Visualizing univariate data</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Week 07</li>
    <li>
      <a href="Week05b.html">Comparing univariate data distributions</a>
    </li>
    <li>
      <a href="Week06a.html">Theoretical Q-Q plot</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Week 08</li>
    <li>
      <a href="Week07a.html">Fits and residuals</a>
    </li>
    <li>
      <a href="Week07b.html">Spread-location plot</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Week 09</li>
    <li>
      <a href="Week08a.html">Re-expressing data</a>
    </li>
    <li>
      <a href="Week08b.html">Letter value summaries</a>
    </li>
    <li>
      <a href="Week08c.html">The Two R’s of EDA</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Bivariate
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Week 10</li>
    <li>
      <a href="Week09a.html">Bivariate analysis</a>
    </li>
    <li>
      <a href="Week09b.html">Resistant lines</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Week 11</li>
    <li>
      <a href="Week10a.html">The third R of EDA: Residuals</a>
    </li>
    <li>
      <a href="Week10b.html">Detecting discontinuities in the data</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Week 12</li>
    <li>
      <a href="http://mgimond.github.io/Tutorial--Stats/05_regression.htmll">Details of the OLS regression method (optional reading)</a>
    </li>
    <li>
      <a href="Week11a.html">Two-way tables</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Misc
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Week 13</li>
    <li>
      <a href="Week12a.html">Creating maps in R</a>
    </li>
    <li class="dropdown-header">Connecting to relational databases</li>
  </ul>
</li>
<li>
  <a href="Data.html">Datasets</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Re-expression and Robustness</h1>

</div>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#a-typical-statistical-approach-the-two-sample-t-test">A typical statistical approach: the two sample t-Test</a></li>
<li><a href="#re-expression">Re-expression</a></li>
<li><a href="#fine-tuning-the-re-expression">Fine-tuning the re-expression</a></li>
<li><a href="#robust-tests">Robust tests</a><ul>
<li><a href="#permutation-test">Permutation test</a></li>
<li><a href="#wilcoxon-rank-sum-test">Wilcoxon rank sum test</a></li>
</ul></li>
<li><a href="#dont-forget-the-outliers">Don’t forget the outliers!</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div style="color:#ff7535; background-color:#fff0ee ;   border-left-style: solid">
<p>This tutorial makes use of the following R package(s): <strong><code>ggplot2</code></strong> and <strong><code>dplyr</code></strong>.</p>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The data represent 1,2,3,4-tetrachlorobenzen (<strong>TCB</strong>) concentrations (in ppb) for two site locations: a reference site free of external contaminants and a <em>cleaned</em> contaminated site (Millard <em>et al.</em>, p. 416-417).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create the two data objects (TCB concentrations for reference and contaminated sites)</span>
Ref &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="fl">0.22</span>,<span class="fl">0.23</span>,<span class="fl">0.26</span>,<span class="fl">0.27</span>,<span class="fl">0.28</span>,<span class="fl">0.28</span>,<span class="fl">0.29</span>,<span class="fl">0.33</span>,<span class="fl">0.34</span>,<span class="fl">0.35</span>,<span class="fl">0.38</span>,<span class="fl">0.39</span>,
          <span class="fl">0.39</span>,<span class="fl">0.42</span>,<span class="fl">0.42</span>,<span class="fl">0.43</span>,<span class="fl">0.45</span>,<span class="fl">0.46</span>,<span class="fl">0.48</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.51</span>,<span class="fl">0.52</span>,<span class="fl">0.54</span>,
          <span class="fl">0.56</span>,<span class="fl">0.56</span>,<span class="fl">0.57</span>,<span class="fl">0.57</span>,<span class="fl">0.6</span>,<span class="fl">0.62</span>,<span class="fl">0.63</span>,<span class="fl">0.67</span>,<span class="fl">0.69</span>,<span class="fl">0.72</span>,<span class="fl">0.74</span>,<span class="fl">0.76</span>,
          <span class="fl">0.79</span>,<span class="fl">0.81</span>,<span class="fl">0.82</span>,<span class="fl">0.84</span>,<span class="fl">0.89</span>,<span class="fl">1.11</span>,<span class="fl">1.13</span>,<span class="fl">1.14</span>,<span class="fl">1.14</span>,<span class="fl">1.2</span>,<span class="fl">1.33</span>)
Cont &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.09</span>,<span class="fl">0.09</span>,<span class="fl">0.09</span>,<span class="fl">0.12</span>,<span class="fl">0.12</span>,<span class="fl">0.14</span>,<span class="fl">0.16</span>,<span class="fl">0.17</span>,<span class="fl">0.17</span>,<span class="fl">0.17</span>,<span class="fl">0.18</span>,<span class="fl">0.19</span>,
          <span class="fl">0.2</span>,<span class="fl">0.2</span>,<span class="fl">0.21</span>,<span class="fl">0.21</span>,<span class="fl">0.22</span>,<span class="fl">0.22</span>,<span class="fl">0.22</span>,<span class="fl">0.23</span>,<span class="fl">0.24</span>,<span class="fl">0.25</span>,<span class="fl">0.25</span>,<span class="fl">0.25</span>,
          <span class="fl">0.25</span>,<span class="fl">0.26</span>,<span class="fl">0.28</span>,<span class="fl">0.28</span>,<span class="fl">0.29</span>,<span class="fl">0.31</span>,<span class="fl">0.33</span>,<span class="fl">0.33</span>,<span class="fl">0.33</span>,<span class="fl">0.34</span>,<span class="fl">0.37</span>,<span class="fl">0.38</span>,
          <span class="fl">0.39</span>,<span class="fl">0.4</span>,<span class="fl">0.43</span>,<span class="fl">0.43</span>,<span class="fl">0.47</span>,<span class="fl">0.48</span>,<span class="fl">0.48</span>,<span class="fl">0.49</span>,<span class="fl">0.51</span>,<span class="fl">0.51</span>,<span class="fl">0.54</span>,<span class="fl">0.6</span>,
          <span class="fl">0.61</span>,<span class="fl">0.62</span>,<span class="fl">0.75</span>,<span class="fl">0.82</span>,<span class="fl">0.85</span>,<span class="fl">0.92</span>,<span class="fl">0.94</span>,<span class="fl">1.05</span>,<span class="fl">1.1</span>,<span class="fl">1.1</span>,<span class="fl">1.19</span>,<span class="fl">1.22</span>,
          <span class="fl">1.33</span>,<span class="fl">1.39</span>,<span class="fl">1.39</span>,<span class="fl">1.52</span>,<span class="fl">1.53</span>,<span class="fl">1.73</span>,<span class="fl">2.35</span>,<span class="fl">2.46</span>,<span class="fl">2.59</span>,<span class="fl">2.61</span>,<span class="fl">3.06</span>,<span class="fl">3.29</span>,
          <span class="fl">5.56</span>,<span class="fl">6.61</span>,<span class="fl">18.4</span>,<span class="fl">51.97</span>,<span class="fl">168.64</span>)

<span class="co"># We&#39;ll create a long-form version of the data for use with some of the functions</span>
<span class="co"># in this exercise</span>
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">Site =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;Cont&quot;</span>,<span class="kw">length</span>(Cont) ), <span class="kw">rep</span>(<span class="st">&quot;Ref&quot;</span>,<span class="kw">length</span>(Ref) ) ),
                  <span class="dt">TCB  =</span> <span class="kw">c</span>(Cont, Ref ) )</code></pre></div>
<p>Our goal is to assess if, overall, the concentrations of TCB at the contaminated site are greater than those at the reference.</p>
</div>
<div id="a-typical-statistical-approach-the-two-sample-t-test" class="section level1">
<h1>A typical statistical approach: the two sample t-Test</h1>
<p>We are interested in answering the question: “Did the cleanup at the contaminated site reduce the concentration of TCB down to background (reference) levels?”. If the question being addressed is part of a decision making process such as “Should we continue with the remediation?” we might want to assess if the difference in TCBs between both sites is “significant” enough to conclude that the TCBs are higher than would be expected if chance alone was the process at play.</p>
<p>A popular statistical procedure used to help address this question is the two sample <a href="http://mgimond.github.io/Tutorial--Stats/02_z_t_tests.html#assumption-of-equal-variance">t-Test</a>. The test is used to assess whether or not the mean concentration between both batches of values are significantly different from one another. The test can be framed in one of three ways: We can see if the batches are similar, if one batch is greater than the other batch, or if one batch is smaller than the other batch. In our case, we will assess if the <code>Cont</code> batch is greater than the <code>Ref</code> batch (this is the <em>alternative</em> hypothesis). We’ll make use of the <code>t.test</code> function and set the parameter <code>alt</code> to <code>&quot;greater&quot;</code> (indicating that we are assessing if the <code>Cont</code> mean is significantly greater than that of <code>Ref</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(Cont, Ref, <span class="dt">alt=</span><span class="st">&quot;greater&quot;</span>)</code></pre></div>
<pre><code>
    Welch Two Sample t-test

data:  Cont and Ref
t = 1.4538, df = 76.05, p-value = 0.07506
alternative hypothesis: true difference in means is greater than 0
95 percent confidence interval:
 -0.4821023        Inf
sample estimates:
mean of x mean of y 
3.9151948 0.5985106 </code></pre>
<p>The test suggests that there is just a small chance (<strong>7.5%</strong>) that the two batches of concentrations are the same. The test outputs the means of each batch: <strong>3.9 ppb</strong> for the contaminated site and <strong>0.6 ppb</strong> for the reference site.</p>
<p>Many ancillary data analysts may stop here and proceed with the decision making process. This is not good practice. To see why, let’s deconstruct the t-test.</p>
<p>First, we need to find out how the test is representing the batches of numbers. The t-test characterizes the <em>location</em> of the batch using the <strong>mean</strong>, and the <em>spread</em> using the <strong>standard deviation</strong>. Nothing more. In essence, the test is reducing the complexity of the batches down to two pairs of numbers.</p>
<p>The t-test uses these pairs of numbers to reconstruct, then compare the distributions. Here are the distributions the t-test <em>thinks</em> it’s comparing:</p>
<p><img src="Week08c_files/figure-html/unnamed-chunk-5-1.png" width="480" /></p>
<p>The red line is the distribution of TCB values for the contaminated site (standard deviation = 20.02) and the black line is the concentration of TCB values for the reference site (standard deviation = 0.28). The red vertical line is the mean concentration of the contaminated site which falls well outside the range of concentrations observed at the reference site.</p>
<blockquote>
<p>As an aside, it’s worth mentioning that the variances are clearly unequal thus violating a basic requirement for the t-test however, R invokes the Welch’s t-test by default to mitigate for unequal variance and sample size. But, Welch’s test does require that the distributions follow a normal theoretical distribution (i.e. they can be different in size but must be normal in shape).</p>
</blockquote>
<p>The spread for the contaminated site is several orders of magnitude greater than that of the reference site. But are these reconstructed distributions really representative of the data?</p>
<p>Let’s plot the density distributions for both batches:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">OP &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(<span class="kw">density</span>(Ref))
<span class="kw">plot</span>(<span class="kw">density</span>(Cont))
<span class="kw">par</span>(OP)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-6-1.png" width="576" /></p>
<p>These are clearly different looking distributions from those assumed by the t-test which should put the t-test results into question.</p>
<p>The t-test is clearly not properly representing the distribution of the two batches. The contaminated site, <code>Cont</code>, has several extreme values that is severely skewing the distribution. We can create a normal q-q plot to see how many values are skewing the distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="kw">qqnorm</span>(Cont, <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.4</span>))
  <span class="kw">qqline</span>(Cont,<span class="dt">lty=</span><span class="dv">3</span>)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-7-1.png" width="288" /></p>
<p>It looks like at least four values (which represent ~5% of the data) are contributing to the strong skew and to a much distorted representation of location and spread. The mean and standard deviation are <strong>not robust</strong> to extreme values. In essence, all it takes is one single outlier to heavily distort the representation of location and spread in our data. We say that the mean and standard deviation have a breakdown point of <code>1/n</code> where <code>n</code> is the sample size.</p>
<p>The median and interquartile range are less sensitive to extreme values. In fact, the median has a breakdown point of <code>n/2</code>. In other words, half of the values would have to be modified to alter the median.</p>
<p>The boxplot makes use of these robust measures of location and spread; let’s compare the batches with and without the extreme (outlier) values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">OP &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>))
<span class="co"># Boxplot with outliers</span>
<span class="kw">boxplot</span>(TCB ~<span class="st"> </span>Site, df, <span class="dt">main=</span><span class="st">&quot;With outliers&quot;</span>)
<span class="co"># Boxplot without outliers</span>
<span class="kw">boxplot</span>(TCB ~<span class="st"> </span>Site, df, <span class="dt">main=</span><span class="st">&quot;Without outliers&quot;</span>, <span class="dt">outline=</span><span class="ot">FALSE</span>)
<span class="kw">par</span>(OP)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-8-1.png" width="576" /></p>
<p>Note that because of the robust nature of the median and interquartile range, the boxplot helps us to spot the outliers. In fact, the boxplot has a breakdown point of <code>n/4</code> (i.e. 25% of the values must be extreme before we see any masking of extreme values). The standard deviation, on the other hand, can be inflated by <em>one</em> extreme value thus <em>masking</em> the potentially problematic values.</p>
<p>One observation that can also be gleaned from this plot is the skewed nature of the <code>Cont</code> data within the interquartile range (IQR). This suggests that even if we were to remove the outliers, the data would violate the normal distribution requirements.</p>
</div>
<div id="re-expression" class="section level1">
<h1>Re-expression</h1>
<p>If we are to use the t-test, we need to make sure that the distributional requirements are met. Even Welch’s modification has one requirement about the distribution: <strong>both spreads must follow a normal distribution</strong>. Let’s compare the batches to a theoretical normal distribution via a theoretical q-q plot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">OP &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>))
<span class="kw">qqnorm</span>(Ref, <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.3</span>))
<span class="kw">qqline</span>(Ref)
<span class="kw">qqnorm</span>(Cont, <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.3</span>))
<span class="kw">qqline</span>(Cont)
<span class="kw">par</span>(OP)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-9-1.png" width="576" /></p>
<p>These batches do not follow the straight line suggesting skewness in the distribution (as was noted with the boxplots). A workaround to this problem is to re-express the batches of values in such a way to render them as close to normal as possible. However, in doing so, we must make sure that both batches are re-expressed in an equal way to facilitate comparison. A popular re-expression used with observational data that exhibit skewness towards higher values is the log transformation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">OP &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>))
<span class="kw">qqnorm</span>(<span class="kw">log</span>(Ref), <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.3</span>))
<span class="kw">qqline</span>(<span class="kw">log</span>(Ref))
<span class="kw">qqnorm</span>(<span class="kw">log</span>(Cont), <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.3</span>))
<span class="kw">qqline</span>(<span class="kw">log</span>(Cont))
<span class="kw">par</span>(OP)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-10-1.png" width="576" /></p>
<p>Log-transforming the concentrations seems to have done a good job in creating normally distributed numbers. Let’s re-run the t-Test on the log-transformed values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(<span class="kw">log</span>(Cont), <span class="kw">log</span>(Ref), <span class="dt">alt=</span><span class="st">&quot;greater&quot;</span>)</code></pre></div>
<pre><code>
    Welch Two Sample t-test

data:  log(Cont) and log(Ref)
t = 0.42589, df = 101.99, p-value = 0.3355
alternative hypothesis: true difference in means is greater than 0
95 percent confidence interval:
 -0.2090447        Inf
sample estimates:
 mean of x  mean of y 
-0.5474262 -0.6195712 </code></pre>
<p>Note that the result differs significantly from that with the raw data. This last run gives us a p-value of <strong>0.34</strong> (suggesting little difference in overall concentrations) whereas the first run gave us a p-value of <strong>0.075</strong> (suggesting that the contaminated site may have had, overall, greater concentration values).</p>
<p>At this point, it’s important to remind ourselves what we are comparing after having log-transformed the data; we are no longer comparing means but the <strong>log of means</strong> instead. More specifically, via mathematical construct, it can be shown that a log-transformation of the data results in testing the hypothesis that the <strong>ratio of mean concentrations are equal to 1</strong>.</p>
</div>
<div id="fine-tuning-the-re-expression" class="section level1">
<h1>Fine-tuning the re-expression</h1>
<p>The log transformation is one of many re-expressions that can be applied to the data. Let’s explore the skewness across different “depths” of the <code>Cont</code> values to see if the skewness is systematic. We’ll use letter value summary plots to help guide us to a reasonable re-expression.</p>
<p>First, we’ll look at the raw contaminated site data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="st">&quot;http://mgimond.github.io/ES218/es218.R&quot;</span>) <span class="co"># Needed to run the lsum() function</span>
<span class="kw">library</span>(ggplot2)

<span class="co"># Generate letter value summary table</span>
Cont.lsum &lt;-<span class="st"> </span><span class="kw">lsum</span>(Cont, <span class="dt">l=</span><span class="dv">7</span>)

<span class="co"># Plot the letter values</span>
<span class="kw">ggplot</span>(Cont.lsum) +<span class="st"> </span><span class="kw">aes</span>(<span class="dt">x=</span>depth, <span class="dt">y=</span>mid, <span class="dt">label=</span>letter) +<span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">                    </span><span class="kw">scale_x_reverse</span>() +<span class="kw">geom_text</span>(<span class="dt">vjust=</span>-.<span class="dv">5</span>, <span class="dt">size=</span><span class="dv">4</span>)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-12-1.png" width="384" /></p>
<p>The data become strongly skewed for 1/32<sup>th</sup> of the data (depth letter <code>C</code>). Let’s now look at the reference site.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Ref.lsum &lt;-<span class="st"> </span><span class="kw">lsum</span>(Ref, <span class="dt">l=</span><span class="dv">7</span>)
<span class="kw">ggplot</span>(Ref.lsum) +<span class="st"> </span><span class="kw">aes</span>(<span class="dt">x=</span>depth, <span class="dt">y=</span>mid, <span class="dt">label=</span>letter) +<span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">                   </span><span class="kw">scale_x_reverse</span>() +<span class="kw">geom_text</span>(<span class="dt">vjust=</span>-.<span class="dv">5</span>, <span class="dt">size=</span><span class="dv">4</span>)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-13-1.png" width="384" /></p>
<p>A skew is also prominent here but a bit more consistent across the depths with a slight drop between depths <code>D</code> and <code>C</code> (16<sup>th</sup> and 32<sup>nd</sup> extreme values).</p>
<p>Next, we will find a power function that re-expresses the values to satisfy the t-test distribution shape requirement. We’ll first look at the log transformation implemented in the last section. Note that we are using the custom Box-cox function <code>bc</code> from the <code>ES218.R</code> source script to transform the data (recall that the log transformation is one of a large family of Box-Cox transformations).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)

df  %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Site) %&gt;%
<span class="st">  </span><span class="kw">do</span>(<span class="kw">lsum</span>( <span class="kw">bc</span>(.$TCB,<span class="dv">0</span>), <span class="dt">l=</span><span class="dv">7</span>) ) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>() +<span class="st"> </span><span class="kw">aes</span>(<span class="dt">x=</span>depth, <span class="dt">y=</span>mid, <span class="dt">label=</span>letter) +<span class="st"> </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">scale_x_reverse</span>() +<span class="kw">geom_text</span>(<span class="dt">vjust=</span>-.<span class="dv">5</span>, <span class="dt">size=</span><span class="dv">4</span>) +<span class="st"> </span><span class="kw">facet_grid</span>(.~Site)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-14-1.png" width="480" /></p>
<p>The log transformation seems to work well with the reference site, but it’s not aggressive enough for the contaminated site. Recall that to ensure symmetry across <em>all</em> levels of the batches, the letter values must follow a straight (horizontal) line. Let’s try a power of -1/2:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df  %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Site) %&gt;%
<span class="st">  </span><span class="kw">do</span>(<span class="kw">lsum</span>( <span class="kw">bc</span>(.$TCB,-<span class="fl">0.5</span>), <span class="dt">l=</span><span class="dv">7</span>) ) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>() +<span class="st"> </span><span class="kw">aes</span>(<span class="dt">x=</span>depth, <span class="dt">y=</span>mid, <span class="dt">label=</span>letter) +<span class="st"> </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">scale_x_reverse</span>() +<span class="kw">geom_text</span>(<span class="dt">vjust=</span>-.<span class="dv">5</span>, <span class="dt">size=</span><span class="dv">4</span>) +<span class="st"> </span><span class="kw">facet_grid</span>(.~Site)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-15-1.png" width="480" /></p>
<p>This seems to be too aggressive. We are facing a situation where attempting to normalize one batch distorts the other batch. Let’s try a compromise and use -.35.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df  %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Site) %&gt;%
<span class="st">  </span><span class="kw">do</span>(<span class="kw">lsum</span>( <span class="kw">bc</span>(.$TCB,-<span class="fl">0.35</span>), <span class="dt">l=</span><span class="dv">7</span>) ) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>() +<span class="st"> </span><span class="kw">aes</span>(<span class="dt">x=</span>depth, <span class="dt">y=</span>mid, <span class="dt">label=</span>letter) +<span class="st"> </span><span class="kw">geom_point</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">scale_x_reverse</span>() +<span class="kw">geom_text</span>(<span class="dt">vjust=</span>-.<span class="dv">5</span>, <span class="dt">size=</span><span class="dv">4</span>) +<span class="st"> </span><span class="kw">facet_grid</span>(.~Site)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-16-1.png" width="480" /></p>
<p>This seems to be a bit better. It’s obvious that we will not find a power transformation that will satisfy both batches, so we will need to make a judgement call and work with a power of -.35 for now.</p>
<p>Let’s compare the re-expressed batches with a normal distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">OP &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>))
<span class="kw">qqnorm</span>(<span class="kw">bc</span>(Ref,-<span class="fl">0.35</span>), <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.3</span>), <span class="dt">main=</span><span class="st">&quot;Reference&quot;</span>)
<span class="kw">qqline</span>(<span class="kw">bc</span>(Ref,-<span class="fl">0.35</span>))
<span class="kw">qqnorm</span>(<span class="kw">bc</span>(Cont,-<span class="fl">0.35</span>), <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.3</span>), <span class="dt">main=</span><span class="st">&quot;Contaminated&quot;</span>)
<span class="kw">qqline</span>(<span class="kw">bc</span>(Cont,-<span class="fl">0.35</span>))
<span class="kw">par</span>(OP)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-17-1.png" width="480" /></p>
<p>The distributions do not look too bad when viewed in a q-q plot. Note how the letter values summary plot can pick up on subtle skewness that may not be apparent in a q-q plot. But is the observed skewed distribution after applying a power transformation really significant? I.e. is it small enough not to bias our t-test results?</p>
<p>Let’s run the t-test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(<span class="kw">bc</span>(Cont,-<span class="fl">0.35</span>), <span class="kw">bc</span>(Ref,-<span class="fl">0.35</span>), <span class="dt">alt=</span><span class="st">&quot;greater&quot;</span>)</code></pre></div>
<pre><code>
    Welch Two Sample t-test

data:  bc(Cont, -0.35) and bc(Ref, -0.35)
t = -1.0495, df = 111.68, p-value = 0.8519
alternative hypothesis: true difference in means is greater than 0
95 percent confidence interval:
 -0.4845764        Inf
sample estimates:
 mean of x  mean of y 
-0.9264188 -0.7386209 </code></pre>
<p>Note that the result differs significantly from that with the raw data. This last run gives us a p-value of <strong>0.85</strong> whereas the first run gave us a p-value of <strong>0.075</strong> and the log-transformed run gave us a p-value of <strong>0.34</strong>. If you tweak the power transformation ever so slightly, you will note that the p-value can change measurably, but fortunately not enough to alter the conclusion that there is no significant difference in concentrations between both sites when comparing the batches using the mean <strong>raised to the -0.35<sup>th</sup></strong> power.</p>
</div>
<div id="robust-tests" class="section level1">
<h1>Robust tests</h1>
<p>It should be clear by now that many of the popular statistical procedures that reduce the data to a mean and standard deviation are not robust to datasets that don’t fit these models well. In fact, most observational data seldom follow a nice normal distribution. The above exercise demonstrates how a very simple implementation of a t-Test can result in a lengthy detour through exploration and re-expression. This can be time consuming when exploring many different datasests. Fortunately there are several alternative statistics that are far less restrictive than the t-Test but serve the same purpose: comparing batches of numbers. These are covered here very superficially for reference.</p>
<div id="permutation-test" class="section level2">
<h2>Permutation test</h2>
<p>The idea here is that if concentrations of TCB come from an identical site, then it should not matter which batch (<code>Ref</code> or <code>Cont</code>) a concentration comes from. By mixing up (permuting) the values across batches, we can come up with a distribution of mean (or median) concentration differences between batches we would expect to get if there was no difference, then compare our observed mean (or median) differences to that of the distribution of simulated mean (or median) differences. In the following example, we will we choose the median over the mean because of its robust measure of location.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Pool the concentrations</span>
Pool &lt;-<span class="st"> </span><span class="kw">c</span>(Ref, Cont)

<span class="co"># Create an empty vector that will store the simulated median differences</span>
med.dif &lt;-<span class="st"> </span><span class="kw">vector</span>()

<span class="co"># Run simulations</span>
for (i in <span class="dv">1</span>:<span class="dv">999</span>){
  <span class="co"># Permute the pooled data then assign the resampled data to each batch</span>
  Pool.rnd &lt;-<span class="st"> </span><span class="kw">sample</span>(Pool, <span class="dt">replace=</span><span class="ot">FALSE</span>)
  <span class="co"># Grab the first batch of values</span>
  Cont.rnd &lt;-<span class="st"> </span>Pool.rnd[<span class="dv">1</span>:<span class="kw">length</span>(Cont)]
  <span class="co"># Grab the second batch of values</span>
  Ref.rnd &lt;-<span class="st"> </span>Pool.rnd[ (<span class="kw">length</span>(Cont)+<span class="dv">1</span>):<span class="kw">length</span>(Pool)]
  <span class="co"># Compute median differences</span>
  med.dif[i] &lt;-<span class="st"> </span><span class="kw">median</span>(Cont.rnd) -<span class="st"> </span><span class="kw">median</span>(Ref.rnd)
}

<span class="co"># Plot the distribution of median differences  </span>
<span class="kw">hist</span>(med.dif)
<span class="co"># Now let&#39;s see where our observed difference in median concentration lies</span>
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">median</span>(Cont) -<span class="st"> </span><span class="kw">median</span>(Ref), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lw=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="Week08c_files/figure-html/unnamed-chunk-19-1.png" width="384" /></p>
<p>We can compute a <em>pseudo</em> p-value from the above. Note that we are interested in the number of simulated values that are <em>different</em> than our observed value (i.e. we’re not concerned with the direction of our value), we are therefore conducting a <em>two-side</em> test whose p-value can be computed as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N.greater &lt;-<span class="st"> </span><span class="kw">sum</span>( (<span class="kw">median</span>(Cont) -<span class="st"> </span><span class="kw">median</span>(Ref)) &gt;=<span class="st"> </span>med.dif) <span class="co"># Number of simulated differences</span>
                                                           <span class="co"># greater than the observed value</span>
n &lt;-<span class="st"> </span><span class="kw">length</span>(med.dif) <span class="co">#number of simulated values</span>
p &lt;-<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span><span class="kw">min</span>(N.greater +<span class="st"> </span><span class="dv">1</span>, n +<span class="st"> </span><span class="dv">1</span> -<span class="st"> </span>N.greater) /<span class="st"> </span>(n +<span class="dv">1</span>)
p</code></pre></div>
<pre><code>[1] 0.202</code></pre>
<p>Here, the p-value gives us the probability that our observed difference in median concentration value is consistent with the expected difference if the two sites were identical. In our example, that probability is around 0.2 suggesting that <em>overall</em>, the concentrations at both sites are relatively the same.</p>
</div>
<div id="wilcoxon-rank-sum-test" class="section level2">
<h2>Wilcoxon rank sum test</h2>
<p>This is another popular alternative to the t-Test. The technical implementation and interpretation is identical to that of the t-Test. It differs from the t-Test in that it is based on the observation ranks as opposed to the observation means. Here, we implement a two-sided test addressing the question <em>“are the differences in concentrations between the sites significant”</em>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(Cont, Ref, <span class="dt">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</code></pre></div>
<pre><code>
    Wilcoxon rank sum test with continuity correction

data:  Cont and Ref
W = 1582, p-value = 0.2423
alternative hypothesis: true location shift is not equal to 0</code></pre>
<p>The p-value (which is similar to that found via the permutation technique) suggests that the difference in <em>overall</em> concentrations is not that great between both sites… despite the presence of a few outliers!</p>
</div>
</div>
<div id="dont-forget-the-outliers" class="section level1">
<h1>Don’t forget the outliers!</h1>
<p>But let’s not loose site of our question which is “Did the cleanup at the contaminated site reduce the concentration of TCB down to background (reference) levels?” It’s obvious once we look at the data that for a few sites, more remediation is needed–particularly for the sites with the three highest concentrations of 6.61, 18.4 and 168.64 ppb and possibly the sites whose concentrations are 5.56 and 6.61. No statistical procedure is needed to come to this conclusion!</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p>Millard S.P, Neerchal N.K., <em>Environmental Statistics with S-Plus</em>, 2001.</p>
</div>


<div class="footer">
<hr/>
<a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/80x15.png" /></a>  Manny Gimond (2017)
</br>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
